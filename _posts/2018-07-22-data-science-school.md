# 데이터 사이언스 스쿨

- [데이터 사이언스 스쿨](https://datascienceschool.net/view-notebook/661128713b654edc928ecb455a826b1d/)에서 공부 내용 노트

## 1 장: 데이터 사이언스란

### 1 절: 데이터 사이언스 학습 안내

##### 데이터 사이언스 학습 안내

### 2 절: 데이터 분석이란

#### 데이터 분석의 소개

#### 1 부: 프로그래밍

## 2 장: 데이터 분석 환경

### 3 절: 데이터 분석을 위한 환경

#### 데이터 분석을 위한 환경 설정

### 4 절: 도커와 리눅스 사용법

#### 셸, 터미널, 콘솔, 프롬프트

#### 도커 툴박스

#### 도커 가상 머신 삭제와 재생성

#### 도커 이미지 설치 및 실행

#### 도커 초간단 사용법

#### 도커 컨테이너와 파일을 공유하기

## 3 장: 파이썬 프로그래밍 시작하기

### 5 절: 파이썬 설치와 사용법

#### 파이썬 설치

#### 파이썬 패키지 설치하기

#### 데이터 분석용 파이썬 패키지 소개

#### IPython 및 주피터 설정

#### 파이썬 처음 사용하기

#### 파이썬 도움말과 자료

### 6 절: 파이썬 기초 문법

#### 파이썬을 계산기로 사용하기

#### 부동소수점 실수 자료형

#### 파이썬으로 글자를 출력하기

#### 파이썬의 문자열 형식화

#### 파이썬 조건문 기초

#### 파이썬 함수

#### 파이썬 for 반복문

#### 파이썬에서 여러 개의 자료를 한 변수에 담기

#### 파이썬에서 리스트 자료형 다루기

#### 리스트와 반복문을 사용하여 계산하기

#### 파이썬에서 딕셔너리 자료형 다루기

#### 파이썬 객체지향 프로그래밍

#### 파이썬 패키지 사용하기

#### 파이썬의 자료형

#### 파이썬의 문자열 인코딩

#### 파이썬에서 날짜와 시간 다루기

## 4 장: 파이썬을 이용한 데이터 분석

### 7 절: NumPy 를 사용한 벡터와 행렬연산

#### NumPy 배열

#### 배열의 생성과 변형

#### 배열의 연산

#### 기술 통계

#### 난수 발생과 카운팅

### 8 절: Pandas 를 사용한 데이터 탐색

#### Pandas 패키지의 소개

#### 데이터 입출력

#### 데이터프레임 인덱서

#### 데이터프레임의 데이터 조작

#### 데이터프레임 인덱스 조작

#### 데이터프레임 합성

#### 피봇테이블과 그룹 분석

#### 시계열 자료 다루기

#### 9 절: 시각화

#### 시각화 패키지 Matplotlib 소개

#### Matplotlib 의 여러가지 플롯

#### Matplotlib 의 삼각 그리드 사용법

#### Seaborn 을 사용한 데이터 분포 시각화

#### Pandas 의 시각화 기능

## 5 장: 데이터 전처리

### 10 절: 파이썬을 사용한 문서 프로세싱

#### NLTK 자연어 처리 패키지

#### KoNLPy 한국어 처리 패키지

#### Scikit-Learn 의 문서 전처리 기능

### 11 절: 파이썬을 사용한 이미지 프로세싱

### 12 절: 파이썬을 사용한 음성 프로세싱

### 13 절: 파이썬을 사용한 지리정보 프로세싱

#### 2 부: 수학

#### 수학 기호

## 6 장: NumPy 로 공부하는 선형 대수 기초

### 14 절: 벡터와 행렬

#### NumPy 를 활용한 선형대수 입문

#### 벡터와 행렬의 연산

### 15 절: 연립방정식과 역행렬

#### 행렬의 성질

#### 연립방정식과 역행렬

### 16 절: 선형대수와 해석기하

#### 선형대수와 해석기하의 기초

#### 좌표와 변환

### 17 절: 행렬의 분해

#### 고윳값 분해

## 7 장: SymPy 와 SciPy 로 공부하는 미적분과 최적화

### 18 절: SymPy 로 공부하는 미분과 적분

#### 함수

#### SymPy 를 사용한 함수 미분

#### 적분

#### 행렬의 미분

#### 19 절: SciPy 를 이용한 최적화

#### 최적화 기초

#### 제한조건이 있는 최적화 문제

#### LP 문제와 QP 문제

## 8 장: 확률론 기초

### 20 절: 확률의 정의와 특성

#### 집합

#### 확률의 수학적 정의

#### 확률의 의미

#### 확률의 성질

### 21 절: 베이즈 정리

#### 결합 확률과 조건부 확률

#### 베이즈 정리

#### 베이즈 정리와 분류 문제

### 22 절: 확률 모형

#### 확률적 데이터

#### 확률 모형

#### 확률 변수

#### 누적 분포 함수와 확률 밀도 함수

#### 기댓값

#### 분산과 표준 편차

#### 모멘트

#### 9 장: SciPy 로 공부하는 확률 변수

### 23 절: SciPy 의 확률 분포 기능

#### SciPy 를 이용한 확률 분포 분석

### 24 절: 이산 확률 분포

#### 베르누이 분포

#### 이항 분포

#### 카테고리 분포

#### 다항 분포

### 25 절: 정규 분포와 통계량 분포

#### 가우시안 정규 분포

#### 스튜던트 t 분포

#### 카이 제곱 분포

#### F 분포

### 26 절: 베이지안 모수 분포 ∗

#### 베타 분포

#### 디리클레 분포

#### 감마 분포

## 10 장: 확률변수의 상관 관계

### 27 절: 결합확률과 조건부확률

#### 다변수 이산확률변수의 결합/조건부확률

#### 다변수 연속확률변수의 결합/조건부확률

### 28 절: 독립과 상관관계

#### 확률 밀도 함수의 독립

#### 공분산과 상관계수

#### 다변수 가우시안 정규 분포

#### 조건부 기댓값

## 11 장: 검정과 추정

#### 29 절: 검정과 유의확률

#### 검정과 모수 추정의 의미

#### 검정과 유의 확률

#### SciPy 를 사용한 기초적인 검정

### 30 절: 모수 추정

#### 모멘트 방법

#### MLE 모수 추정의 원리

#### MLE 모수 추정의 예

### 31 절: 베이지안 모수추정 ∗

#### 베이지안 모수 추정

#### 몬테카를로 베이지안 분석

#### 3 부: 통계분석

## 12 장: 통계분석 및 머신러닝 패키지

### 32 절: StatsModels 패키지 소개

#### StatsModels 패키지 소개

#### StatsModels 의 샘플 데이터

### 33 절: Scikit-Learn 패키지 소개

#### Scikit-Learn 패키지 소개

#### Scikit-Learn 의 샘플 데이터

## 13 장: StatsModels 로 공부하는 회귀분석

### 34 절: 선형회귀분석의 기초

#### 회귀 분석용 샘플 데이터

#### 회귀분석용 가상 데이터 생성 방법

#### 선형 회귀분석의 기초

#### 회귀 분석의 기하학

#### Partial Regression

#### 확률론적 선형회귀모형

#### 레버리지와 아웃라이어

### 35 절: 입력변수가 카테고리값인 경우

#### R 스타일 모형 정의

#### 입력변수가 카테고리값인 경우

### 36 절: 예측성능의 진단과 비교

#### 분산 분석과 모형 성능

#### 회귀분석 결과의 진단

#### 스케일링과 변수 변환

#### 다중공선성

#### PCA

### 37 절: 과최적화와 교차 검증

#### 다항 회귀와 과최적화

#### 교차 검증

#### 정규화 선형회귀

#### 최적 정규화

### 38 절: 추천시스템 ∗

#### 추천 시스템의 기초

## 14 장: StatsModels 로 시계열 분석하기

#### 39 절: 확률 과정

#### 시계열 자료와 확률 과정

#### 정상 확률 과정과 비정상 확률 과정

#### 백색 잡음

#### 이산 시간 랜덤 워크

#### 일반 선형 확률 과정 모형

### 40 절: ARIMA 모형

#### StatsModels 의 ARMA 클래스

#### 1 차 Moving Average (MA) 모형

#### 다차 Moving Average (MA) 모형

#### 1 차 Autoregressive (AR) 모형

#### 2 차 Autoregressive (AR) 모형

#### ARMA 모형

#### ARIMA 모형

#### Dickey-Fuller 단위근 검정

#### 단순 Seasonal ARIMA 모형

#### Multiplicated Seasonal ARIMA 모형

### 41 절: 모형의 추정 및 진단

#### 확률 과정 모형을 추정하는 방법

#### 결정론적 추세 추정

#### 샘플 자기상관계수 함수

#### 편자기상관계수 함수

#### ARIMA 모형 차수 결정의 예

#### StatsModels 의 ARMA 클래스

#### ARMA 모형 모수 추정

#### 잔차 분석

#### Seasonal ARIMA 모형 추정의 예

### 42 절: 상태 공간 모형과 칼만 필터 ∗

#### 상태 공간 모형의 소개

#### StatsModels 의 Kalman Filter 클래스

#### 로컬 레벨 모형

#### 로컬 선형 추세 모형

#### 칼만 필터 공식의 유도

#### 히든 마코프 모형

#### 4 부: 머신러닝

## 15 장: 비지도 학습

### 43 절: 클러스터링 ∗

#### K-Means 클러스터링

#### Affinity Propagation

#### 계층적 클러스터링

#### 가우시안 혼합모형과 EM 방법

## 16 장: Scikit-Learn 을 사용한 머신러닝

### 44 절: 분류의 기초

#### 분류용 샘플 데이터 소개

#### 분류용 가상 데이터 생성 방법

#### Scikit-Learn 의 전처리 기능

#### 분류의 기초

#### 다중 클래스 분류

#### 분류 성능 평가

### 45 절: 로지스틱 회귀분석

#### 로지스틱 회귀분석

### 46 절: QDA 와 나이브 베이즈 모형

#### QDA 와 LDA

#### 나이브 베이즈 분류 모형

#### 나이브 베이즈 분류 모형을 이용한 감성 분석

### 47 절: 의사 결정 나무

#### 엔트로피

#### 의사 결정 나무

### 48 절: 앙상블 방법

#### 모형 결합의 기초

#### 부스팅 방법

#### 49 절: 퍼셉트론과 서포트벡터 머신

#### 퍼셉트론

#### 서포트 벡터 머신

### 50 절: 커널 서포트 벡터 머신

#### 커널 서포트 벡터 머신

### 51 절: 모형 최적화

#### 모형 최적화

### 52 절: 비대칭 데이터 문제

#### 비대칭 데이터 문제

## 17 장: 신경망 모형

### 53 절: 신경망 모형 기초

#### 신경망 기초 이론

#### Theano 패키지 소개

#### TensorFlow 패키지 소개

#### Keras 패키지를 사용한 신경망 구현

### 54 절: 신경망 성능 개선

#### 그레디언트 소멸 문제

#### 신경망 성능 개선

#### 신경망 최적화 방법

### 55 절: CNN

#### Convolutional Neural Network 기초

#### Keras 를 이용한 CNN 구현 - MNIST

#### Keras 를 이용한 CNN 구현 - CIFAR10

#### Image Augmentation

#### VGG16

### 56 절: 확률론적 언어모형과 RNN

#### 확률론적 언어 모형

#### 단어 임베딩과 word2vec

#### CBOW in Keras

#### RNN 기본 구조와 Keras 를 사용한 RNN 구현

#### RNN Text Generation

#### 신경망 언어 번역

### 57 절: Generative Adversarial Network∗

#### Keras Model

#### DC GAN

#### 교재 및 참고 문헌

#### 머신 러닝 관련 참고 문헌
